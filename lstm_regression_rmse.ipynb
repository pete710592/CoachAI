{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import requirements & Parameters setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import glob\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, LSTM, TimeDistributed, Input, ReLU\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from utils.functions import checkDirExist, deleteDir\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 1000\n",
    "\n",
    "# set model name & model directory\n",
    "model_name = '20201223_lstm-rmse-position5-trajectory3-all-diff-32-8-batchsize128-relu-epoch1000'\n",
    "model_dir = os.path.join(os.getcwd(), 'models/'+model_name)\n",
    "log_dir = os.path.join(os.getcwd(), 'logs/'+model_name)\n",
    "checkDirExist(model_dir)\n",
    "\n",
    "# get train data (csv)\n",
    "train_dir = os.path.join(os.getcwd(), 'dataset/position_5/trajectory-all/dataset-3/train/')\n",
    "train_list = glob.glob(train_dir + \"*.csv\")\n",
    "\n",
    "# split validation\n",
    "random.Random(4).shuffle(train_list)\n",
    "vaild_num = int(len(train_list)*0.1)\n",
    "valid_list = train_list[:vaild_num]\n",
    "train_list = train_list[vaild_num:]\n",
    "\n",
    "# get test data (csv)\n",
    "test_dir = os.path.join(os.getcwd(), 'dataset/evaluation/1_player/')\n",
    "test_list = glob.glob(test_dir + \"*.csv\")\n",
    "\n",
    "print('train: ', len(train_list))\n",
    "print('valid: ', len(valid_list))\n",
    "print('test: ', len(test_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic allocation for GPU (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True   # Dynamic allocation\n",
    "sess = tf.Session(config=config)\n",
    "KTF.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Validation / Test generator definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator():\n",
    "    while(True):\n",
    "        random.Random(4).shuffle(train_list)\n",
    "        for i, csv in enumerate(train_list):\n",
    "            df = pd.read_csv(csv)\n",
    "            data = []\n",
    "            diff = []\n",
    "            for idx in df.index:\n",
    "                diff.append(df.loc[idx, ['X', 'Y']].tolist())\n",
    "            label = df.loc[0, ['Speed', 'Angle_H', 'Angle_V']].tolist()\n",
    "\n",
    "            diff = np.diff(np.array(diff), axis=0).tolist()  # compute diff\n",
    "            for idx, diff in enumerate(diff):\n",
    "                data.append([idx])  # timestep\n",
    "                data[idx].extend(diff)  # diff\n",
    "                data[idx].append(np.linalg.norm(diff))  # Euclidean distance\n",
    "#                 data[idx].append(math.atan2(diff[1], diff[0]))  # arctan(y2-y1/x2-x1)\n",
    "            \n",
    "            x_train = np.expand_dims(data, axis=0)\n",
    "            y_train = np.expand_dims(np.array(label), axis=0)\n",
    "\n",
    "            y_train = y_train.astype(np.float32)\n",
    "            y_train[:, 0] = (y_train[:, 0]-20)/120\n",
    "            y_train[:, 1] = (y_train[:, 1]-10)/60\n",
    "            y_train[:, 2] = (y_train[:, 2]-10)/30\n",
    "\n",
    "            yield x_train, y_train, [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_generator():\n",
    "    while(True):\n",
    "        for i, csv in enumerate(valid_list):\n",
    "            df = pd.read_csv(csv)\n",
    "            data = []\n",
    "            diff = []\n",
    "            for idx in df.index:\n",
    "                diff.append(df.loc[idx, ['X', 'Y']].tolist())\n",
    "            label = df.loc[0, ['Speed', 'Angle_H', 'Angle_V']].tolist()\n",
    "\n",
    "            diff = np.diff(np.array(diff), axis=0).tolist()  # compute diff\n",
    "            for idx, diff in enumerate(diff):\n",
    "                data.append([idx])  # timestep\n",
    "                data[idx].extend(diff)  # diff\n",
    "                data[idx].append(np.linalg.norm(diff))  # Euclidean distance\n",
    "#                 data[idx].append(math.atan2(diff[1], diff[0]))  # arctan(y2-y1/x2-x1)\n",
    "            \n",
    "            x_valid = np.expand_dims(data, axis=0)\n",
    "            y_valid = np.expand_dims(np.array(label), axis=0)\n",
    "\n",
    "            y_valid = y_valid.astype(np.float32)\n",
    "            y_valid[:, 0] = (y_valid[:, 0]-20)/120\n",
    "            y_valid[:, 1] = (y_valid[:, 1]-10)/60\n",
    "            y_valid[:, 2] = (y_valid[:, 2]-10)/30\n",
    "\n",
    "            yield x_valid, y_valid, [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_generator():\n",
    "    for i, csv in enumerate(test_list):\n",
    "        df = pd.read_csv(csv)\n",
    "        data = []\n",
    "        diff = []\n",
    "        for idx in df.index:\n",
    "            diff.append(df.loc[idx, ['X', 'Y']].tolist())\n",
    "        label = df.loc[0, ['Speed', 'Angle_H', 'Angle_V']].tolist()\n",
    "\n",
    "        diff = np.diff(np.array(diff), axis=0).tolist()  # compute diff\n",
    "        for idx, diff in enumerate(diff):\n",
    "            data.append([idx])  # timestep\n",
    "            data[idx].extend(diff)  # diff\n",
    "            data[idx].append(np.linalg.norm(diff))  # Euclidean distance\n",
    "#             data[idx].append(math.atan2(diff[1], diff[0]))  # arctan(y2-y1/x2-x1)\n",
    "\n",
    "        x_test = np.expand_dims(data, axis=0)\n",
    "        y_test = np.expand_dims(np.array(label), axis=0)\n",
    "        split_percentage = csv.split('_predict')[0].split('_')[-1]\n",
    "#         split_percentage = csv.split('predict_')[1].split('.csv')[0]\n",
    "\n",
    "        x_test = x_test.astype(np.float32)\n",
    "        y_test = y_test.astype(np.float32)\n",
    "        yield x_test, y_test, split_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True, recurrent_dropout=0.2, input_shape=(None, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(16, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(8, return_sequences=False))\n",
    "model.add(Dense(3))\n",
    "model.add(ReLU())\n",
    "model.compile(loss=root_mean_squared_error, optimizer=\"adam\", metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "traj = Input((None, 4))\n",
    "feature = LSTM(32, return_sequences=True, recurrent_dropout=0.2)(traj)\n",
    "speed = LSTM(32, return_sequences=True, recurrent_dropout=0.2)(feature)\n",
    "speed = LSTM(16, return_sequences=True, recurrent_dropout=0.2)(speed)\n",
    "speed = LSTM(16, return_sequences=True, recurrent_dropout=0.2)(speed)\n",
    "speed = LSTM(8, return_sequences=False)(speed)\n",
    "speed = Dense(1, name='speed')(speed)\n",
    "\n",
    "angle = LSTM(8, return_sequences=False)(feature)\n",
    "angle = Dense(2, name=\"angle\")(angle)\n",
    "output = keras.layers.concatenate([speed, angle])\n",
    "model = Model(traj, output)\n",
    "model.compile(loss=root_mean_squared_error, optimizer=\"adam\", metrics=['mae'])\n",
    "model.summary()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_file = os.path.join(model_dir, model_name+'.png')\n",
    "plot_model(model, show_shapes=True, show_layer_names=True, to_file=plot_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training logs\n",
    "model_cbk = keras.callbacks.TensorBoard(log_dir=\"logs/{}\".format(model_name), histogram_freq=1)\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, mode='min')\n",
    "\n",
    "# save best model weights\n",
    "model_mckp = keras.callbacks.ModelCheckpoint(os.path.join(model_dir, model_name+\".h5\"), \n",
    "                                             monitor='val_loss', \n",
    "                                             save_best_only=True, \n",
    "                                             mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator(), \n",
    "                    steps_per_epoch=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    validation_data=valid_generator(),\n",
    "                    validation_steps=len(valid_list),\n",
    "                    callbacks=[model_mckp, model_cbk])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Load model\n",
    "model_dir = \"models/20201216_lstm-rmse-position5-trajectory3-all-diff-euclidean-32-8-batchsize128-relu-epoch1000/\"\n",
    "model_name = \"20201216_lstm-rmse-position5-trajectory3-all-diff-euclidean-32-8-batchsize128-relu-epoch1000.h5\"\n",
    "model_path = os.path.join(model_dir, model_name)\n",
    "model = keras.models.load_model(model_path,\n",
    "                                custom_objects={'root_mean_squared_error': root_mean_squared_error})\n",
    "\n",
    "# eval_his = model.evaluate_generator(test_generator(), steps=len(test_list), verbose=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "predict = model.predict_generator(test_generator(), verbose=1, steps=len(test_list))\n",
    "\n",
    "predict[:, 0] = predict[:, 0] * 120 + 20\n",
    "predict[:, 1] = predict[:, 1] * 60 + 10\n",
    "predict[:, 2] = predict[:, 2] * 30 + 10\n",
    "\n",
    "# Present as dataframe\n",
    "df = pd.DataFrame()\n",
    "for i, (_, y_test, split_percentage) in enumerate(test_generator()):\n",
    "    df.loc[i, 'Speed'] = y_test[:, 0]\n",
    "    df.loc[i, 'Angle_H'] = y_test[:, 1]\n",
    "    df.loc[i, 'Angle_V'] = y_test[:, 2]\n",
    "    df.loc[i, 'split'] = split_percentage\n",
    "    df.loc[i, 'Predict(Speed)'] = predict[:,0][i]\n",
    "    df.loc[i, 'Predict(Angle_H)'] = predict[:,1][i]\n",
    "    df.loc[i, 'Predict(Angle_V)'] = predict[:,2][i]\n",
    "\n",
    "# Adjust data type\n",
    "df = df.astype({'Speed': 'int32',\n",
    "                'Angle_H': 'int32',\n",
    "                'Angle_V': 'int32',\n",
    "                'Predict(Speed)': 'int32',\n",
    "                'Predict(Angle_H)': 'int32',\n",
    "                'Predict(Angle_V)': 'int32'})\n",
    "\n",
    "# Caculate Loss\n",
    "for i in df.index:\n",
    "    target = df.loc[i, ['Speed', 'Angle_H', 'Angle_V']].tolist()\n",
    "    target[0] = (target[0]-20)/120\n",
    "    target[1] = (target[1]-10)/60\n",
    "    target[2] = (target[2]-10)/30\n",
    "    pred = df.loc[i, ['Predict(Speed)', 'Predict(Angle_H)', 'Predict(Angle_V)']].tolist()\n",
    "    pred[0] = (pred[0]-20)/120\n",
    "    pred[1] = (pred[1]-10)/60\n",
    "    pred[2] = (pred[2]-10)/30\n",
    "    \n",
    "    mae = mean_absolute_error(target, pred)\n",
    "    rmse = np.sqrt(mean_squared_error(target, pred))\n",
    "    df.loc[i, 'MAE'] = np.around(mae, decimals=6)\n",
    "    df.loc[i, 'RMSE'] = np.around(rmse, decimals=6)\n",
    "\n",
    "df.sort_values(\"split\", inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caculate mean loss\n",
    "last_idx = len(df)\n",
    "df.loc[last_idx, 'MAE'] = df['MAE'].mean()\n",
    "df.loc[last_idx, 'RMSE'] = df['RMSE'].mean()\n",
    "\n",
    "# Save result to csv\n",
    "result_dir = os.path.join(os.getcwd(), 'predictions/')\n",
    "checkDirExist(result_dir)\n",
    "df.to_csv(os.path.join(result_dir, model_name+'.csv'))\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['mean_absolute_error'])\n",
    "plt.plot(history.history['val_mean_absolute_error'])\n",
    "plt.title('mae')\n",
    "plt.ylabel('mae')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Jupyter(.ipynb) to Python(.py) (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyter nbconvert --to script lstm_regression_rmse.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
